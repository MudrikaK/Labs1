{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s9X2kU2drQgj"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aCm3ZQXVrQgm"
   },
   "source": [
    "# Lab 8.1: Bagging\n",
    "\n",
    "INSTRUCTIONS:\n",
    "\n",
    "- Read the guides and hints then create the necessary analysis and code to find an answer and conclusion for the scenario below.\n",
    "- The baseline results (minimum) are:\n",
    "    - **Accuracy** = 0.9667\n",
    "    - **ROC AUC**  = 0.9614\n",
    "- Try to achieve better results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "92pwAXoxrQgo"
   },
   "source": [
    "# Foreword\n",
    "It is common that companies and professionals start with the data immediately available. Although this approach works, ideally the first step is to identify the problem or question and only then identify and obtain the set of data that can help to solve or answer the problem.\n",
    "\n",
    "Also, given the current abundance of data, processing power and some particular machine learning methods, there could be a temptation to use ALL the data available. **Quality** is _**better**_ than **Quantity**!\n",
    "\n",
    "Part of calling this discipline **Data Science** is that it is supposed to follow a process and not reach conclusions without support from evidence.\n",
    "\n",
    "Moreover, it is a creative, exploratory, laborious, iterative and interactive process. It is part of the process to repeat, review and change when finding a dead-end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RSD00QfUrQgq"
   },
   "source": [
    "## Scenario: Predicting Breast Cancer\n",
    "The dataset you are going to be using for this laboratory is popularly known as the **Wisconsin Breast Cancer** dataset. The task related to it is Classification.\n",
    "\n",
    "The dataset contains a total number of _10_ features labelled in either **benign** or **malignant** classes. The features have _699_ instances out of which _16_ feature values are missing. The dataset only contains numeric values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yQBpCdC7rQgr"
   },
   "source": [
    "# Step 1: Define the problem or question\n",
    "Identify the subject matter and the given or obvious questions that would be relevant in the field.\n",
    "\n",
    "## Potential Questions\n",
    "List the given or obvious questions.\n",
    "\n",
    "## Actual Question\n",
    "Choose the **one** question that should be answered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a5EL9yvkrQgt"
   },
   "source": [
    "# Step 2 (Answer): Find the Data\n",
    "[Breast Cancer Wisconsin (Original) Data Set](https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original))\n",
    "\n",
    "## Title: Breast Cancer Wisconsin (Original) DataSet\n",
    "[Link](https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.names)\n",
    "\n",
    "- **Citation Request**\n",
    "\n",
    "    This breast cancer databases was obtained from the **University of Wisconsin Hospitals**, **Madison** from **Dr. William H. Wolberg**. If you publish results when using this database, then please include this information in your acknowledgements.\n",
    "\n",
    "- **Title**\n",
    "\n",
    "    Wisconsin Breast Cancer Database (January 8, 1991)\n",
    "\n",
    "- **Sources**\n",
    "    - Creator:\n",
    "            Dr. WIlliam H. Wolberg (physician)\n",
    "            University of Wisconsin Hospitals\n",
    "            Madison, Wisconsin\n",
    "            USA\n",
    "    - Donor:\n",
    "            Olvi Mangasarian (mangasarian@cs.wisc.edu)\n",
    "            Received by David W. Aha (aha@cs.jhu.edu)\n",
    "    - Date:\n",
    "            15 July 1992\n",
    "\n",
    "- **Past Usage**\n",
    "\n",
    "    Attributes 2 through 10 have been used to represent instances.\n",
    "    Each instance has one of 2 possible classes: benign or malignant.\n",
    "\n",
    "    1. Wolberg,~W.~H., \\& Mangasarian,~O.~L. (1990). Multisurface method of pattern separation for medical diagnosis applied to breast cytology. In _Proceedings of the National Academy of Sciences_, _87_, 9193--9196.\n",
    "        - Size of data set: only 369 instances (at that point in time)\n",
    "        - Collected classification results: 1 trial only\n",
    "        - Two pairs of parallel hyperplanes were found to be consistent with 50% of the data\n",
    "            - Accuracy on remaining 50% of dataset: 93.5%\n",
    "        - Three pairs of parallel hyperplanes were found to be consistent with 67% of data\n",
    "            - Accuracy on remaining 33% of dataset: 95.9%\n",
    "\n",
    "    2. Zhang,~J. (1992). Selecting typical instances in instance-based learning. In _Proceedings of the Ninth International Machine Learning Conference_ (pp. 470-479). Aberdeen, Scotland: Morgan Kaufmann.\n",
    "        - Size of data set: only 369 instances (at that point in time)\n",
    "        - Applied 4 instance-based learning algorithms \n",
    "        - Collected classification results averaged over 10 trials\n",
    "        - Best accuracy result: \n",
    "            - 1-nearest neighbor: 93.7%\n",
    "            - trained on 200 instances, tested on the other 169\n",
    "        - Also of interest:\n",
    "            - Using only typical instances: 92.2% (storing only 23.1 instances)\n",
    "            - trained on 200 instances, tested on the other 169\n",
    "\n",
    "- **Relevant Information**\n",
    "\n",
    "    Samples arrive periodically as Dr. Wolberg reports his clinical cases. The database therefore reflects this chronological grouping of the data. This grouping information appears immediately below, having been removed from the data itself:\n",
    "\n",
    "        Group 1: 367 instances (January 1989)\n",
    "        Group 2:  70 instances (October 1989)\n",
    "        Group 3:  31 instances (February 1990)\n",
    "        Group 4:  17 instances (April 1990)\n",
    "        Group 5:  48 instances (August 1990)\n",
    "        Group 6:  49 instances (Updated January 1991)\n",
    "        Group 7:  31 instances (June 1991)\n",
    "        Group 8:  86 instances (November 1991)\n",
    "        ---------------------------------------------------------------\n",
    "        Total:   699 points (as of the donated datbase on 15 July 1992)\n",
    "\n",
    "    Note that the results summarized above in Past Usage refer to a dataset of size 369, while Group 1 has only 367 instances. This is because it originally contained 369 instances; 2 were removed. The following statements summarizes changes to the original Group 1's set of data:\n",
    "\n",
    "        #####  Group 1 : 367 points: 200B 167M (January 1989)\n",
    "        #####  Revised Jan 10, 1991: Replaced zero bare nuclei in 1080185 & 1187805\n",
    "        #####  Revised Nov 22,1991: Removed 765878,4,5,9,7,10,10,10,3,8,1 no record\n",
    "        #####                  : Removed 484201,2,7,8,8,4,3,10,3,4,1 zero epithelial\n",
    "        #####                  : Changed 0 to 1 in field 6 of sample 1219406\n",
    "        #####                  : Changed 0 to 1 in field 8 of following sample:\n",
    "        #####                  : 1182404,2,3,1,1,1,2,0,1,1,1\n",
    "\n",
    "- **Number of Instances**\n",
    "    - 699 (as of 15 July 1992)\n",
    "\n",
    "- **Number of Attributes**\n",
    "    - 10 plus the class attribute\n",
    "\n",
    "- **Attribute Information**\n",
    "\n",
    "    Class attribute has been moved to last column\n",
    "\n",
    "         #  Attribute                   Domain\n",
    "        --- --------------------------- -----------\n",
    "         1. Sample code number          id number\n",
    "         2. Clump Thickness             1 - 10\n",
    "         3. Uniformity of Cell Size     1 - 10\n",
    "         4. Uniformity of Cell Shape    1 - 10\n",
    "         5. Marginal Adhesion           1 - 10\n",
    "         6. Single Epithelial Cell Size 1 - 10\n",
    "         7. Bare Nuclei                 1 - 10\n",
    "         8. Bland Chromatin             1 - 10\n",
    "         9. Normal Nucleoli             1 - 10\n",
    "        10. Mitoses                     1 - 10\n",
    "        11. Class                       (2 for benign, 4 for malignant)\n",
    "\n",
    "- **Missing attribute values**\n",
    "    - 16\n",
    "\n",
    "    There are 16 instances in Groups 1 to 6 that contain a single missing (i.e., unavailable) attribute value, now denoted by \"?\".  \n",
    "\n",
    "- **Class distribution**\n",
    "    - Benign: 458 (65.5%)\n",
    "    - Malignant: 241 (34.5%)\n",
    "    \n",
    "- **Data**\n",
    "    - [Download](https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "29Y8teMmrQgu"
   },
   "source": [
    "# Step 3: Read the Data\n",
    "- Read the data\n",
    "- Perform some basic structural cleaning to facilitate the work\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1000025</th>\n",
       "      <th>5</th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "      <th>1.2</th>\n",
       "      <th>2</th>\n",
       "      <th>1.3</th>\n",
       "      <th>3</th>\n",
       "      <th>1.4</th>\n",
       "      <th>1.5</th>\n",
       "      <th>2.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017122</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1000025  5   1  1.1  1.2  2 1.3  3  1.4  1.5  2.1\n",
       "0  1002945  5   4    4    5  7  10  3    2    1    2\n",
       "1  1015425  3   1    1    1  2   2  3    1    1    2\n",
       "2  1016277  6   8    8    1  3   4  3    7    1    2\n",
       "3  1017023  4   1    1    3  2   1  3    1    1    2\n",
       "4  1017122  8  10   10    8  7  10  9    7    1    4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"breast-cancer-wisconsin-data-old.csv\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d-weYwx7rQgw"
   },
   "source": [
    "# Step 4: Explore and Clean the Data\n",
    "- Perform some initial simple **EDA** (Exploratory Data Analysis)\n",
    "- Check for\n",
    "    - **Number of features**\n",
    "    - **Data types**\n",
    "    - **Domains, Intervals**\n",
    "    - **Outliers** (are they valid or expurious data [read or measure errors])\n",
    "    - **Null** (values not present or coded [as zero of empty strings])\n",
    "    - **Missing Values** (coded [as zero of empty strings] or values not present)\n",
    "    - **Coded content** (classes identified by numbers or codes to represent absence of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.shape # It is always a good idea to understand your data\n",
    "# data.isnull().sum() # Find out how many cells have missing values\n",
    "# data=data.dropna(how='any') # Dropping any rows that has missing values\n",
    "\n",
    "\n",
    "raw_data = pd.read_table(\"breast-cancer-wisconsin-data-old.csv\", delimiter=',', na_values=['?'])\n",
    "data = raw_data.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6gt8rX8RrQgy"
   },
   "source": [
    "# Step 5: Prepare the Data\n",
    "- Deal with the data as required by the modelling technique\n",
    "    - **Outliers** (remove or adjust if possible or necessary)\n",
    "    - **Null** (remove or interpolate if possible or necessary)\n",
    "    - **Missing Values** (remove or interpolate if possible or necessary)\n",
    "    - **Coded content** (transform if possible or necessary [str to number or vice-versa])\n",
    "    - **Normalisation** (if possible or necessary)\n",
    "    - **Feature Engeneer** (if useful or necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['thickness', 'size', 'shape', 'adhesion', 'single', 'nuclei',\\n       'chromatin', 'nucleoli', 'mitosis'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9ce65142442c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"thickness\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"size\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"adhesion\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"single\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"nuclei\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"chromatin\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"nucleoli\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"mitosis\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2804\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2806\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m         )\n\u001b[1;32m   1555\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1638\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1639\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1640\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1642\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['thickness', 'size', 'shape', 'adhesion', 'single', 'nuclei',\\n       'chromatin', 'nucleoli', 'mitosis'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "x=data[['thickness','size','shape','adhesion','single','nuclei','chromatin','nucleoli','mitosis']]\n",
    "y=data['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z97YHdNerQgz"
   },
   "source": [
    "# Step 6: Modelling\n",
    "Refer to the Problem and Main Question.\n",
    "- What are the input variables (features)?\n",
    "- Is there an output variable (label)?\n",
    "- If there is an output variable:\n",
    "    - What is it? -> Y is the output variable\n",
    "    - What is its type? numpy.ndarray\n",
    "- What type of Modelling is it?\n",
    "    - [Yes] Supervised\n",
    "    - [ ] Unsupervised \n",
    "- What type of Modelling is it?\n",
    "    - [Yes] Regression\n",
    "    - [ ] Classification (binary) \n",
    "    - [ ] Classification (multi-class)\n",
    "    - [ ] Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_61ti1HFrQg1"
   },
   "source": [
    "# Step 7: Split the Data\n",
    "\n",
    "Need to check for **Supervised** modelling:\n",
    "- Number of known cases or observations\n",
    "- Define the split in Training/Test or Training/Validation/Test and their proportions\n",
    "- Check for unbalanced classes and how to keep or avoid it when spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.40, random_state=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dsVE4u7GrQg3"
   },
   "source": [
    "# Step 8: Define and Fit Models\n",
    "\n",
    "Define the model and its hyper-parameters.\n",
    "\n",
    "Consider the parameters and hyper-parameters of each model at each (re)run and after checking the efficiency of a model against the training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "48tgELX9rQg4"
   },
   "source": [
    "# Step 9: Verify and Evaluate the Training Model\n",
    "- Use the **training** data to make predictions\n",
    "- Check for overfitting\n",
    "- What metrics are appropriate for the modelling approach used\n",
    "- For **Supervised** models:\n",
    "    - Check the **Training Results** with the **Training Predictions** during development\n",
    "- Analyse, modify the parameters and hyper-parameters and repeat (within reason) until the model does not improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "y_pred_class=logreg.predict(x_test)\n",
    "print(type(y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WGKHPx9srQg6"
   },
   "source": [
    "# Step 10: Make Predictions and Evaluate the Test Model\n",
    "**NOTE**: **Do this only after not making any more improvements in the model**.\n",
    "\n",
    "- Use the **test** data to make predictions\n",
    "- For **Supervised** models:\n",
    "    - Check the **Test Results** with the **Test Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9708029197080292\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9665770045212614"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iAz6pXN3rQg7"
   },
   "source": [
    "# Step 11: Solve the Problem or Answer the Question\n",
    "The results of an analysis or modelling can be used:\n",
    "- As part of a product or process, so the model can make predictions when new input data is available\n",
    "- As part of a report including text and charts to help understand the problem\n",
    "- As input for further questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IS5Tc4z9FoYy"
   },
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mxI2We9OFpfs"
   },
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "81DoNxN1FqGN"
   },
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RERADKgNFq9T"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > > Â© 2019 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DSIA Lab-8_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
